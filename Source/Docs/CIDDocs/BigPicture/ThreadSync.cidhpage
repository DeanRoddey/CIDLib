<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE HelpPage PUBLIC "urn:charmedquark.com:CIDLib-Documentation.DTD" "CIDLibDocs.DTD">

<HelpPage>
    <Title>Thread Synchronization</Title>

    <HelpText>

        <P>Threads in general are covered in a separate section, see Threads to the left. Since threads are a bigger topic, synchronization is split out here to be discussed separately.</P>

        <Note>I won't get into a lot of example code here, since there would be too much. This is stuff better presented in the context of the sample programs that come with CIDLib.</Note>

        <P>CIDLib provides the usual mechanisms for synchronizing threads, e.g. mutexes, critical sections, and events. Publish/Subscribe is also a possible way to 'synchronize' loosely coupled threads. Mutexes are the most common means. I won't go into detail about mutexes, that's a general computer science topic and you can go dig into it separately. I'll assume here you understand how they work.</P>

        <P>The most common way to use a mutex is via a mutex lock janitor class. See Janitors to the left for more information on that topic. That lets you safely lock a mutex for a given scope and insure it gets unlocked even if an exception occurs. Here is an example, assuming that this class as a mutex and probably multiple threads are running within it and calling this method (or possibly one thread in the object and multiple external threads.)</P>

        <Code>
        tCIDLib::TVoid TSomeClass::DoSomething()
        {
            TMtxLocker mtxlSync(&amp;amp;m_mtxSync);

            // Do stuff that needs to be locked here
        }
        </Code>

        <P>Of course you aways want to keep the amount of code within a lock as absolutely short as possible. So you don't need to lock for the whole method. And you often will want to create a faux scope purely for locking, such as:</P>

        <Code>
        tCIDLib::TVoid TSomeClass::DoSomething()
        {
            // Do prelimimary setup

            // Lock and do safe stuff
            {
                TMtxLocker mtxlSync(&amp;amp;m_mtxSync);
                // Do stuff that needs to be locked here
            }

            // And we can now work safely on stuff left for us by the safe code
        }
        </Code>


        <SubSecTitle>Critical Section vs. Mutex</SubSecTitle>

        <P>Critical sections and mutexes do the same thing. The only difference is that critical sections can be lighter weight. But, they are really only appropriate to use if the amount of time you need to lock is very short and there is not very often any contention (i.e. the time locked is very short and threads aren't hitting that locked path rapidly so most of the time a thread doing the lock just gets right in.) So, if you just needed to safely add some incoming value to a counter, or add a string to a list, a critical section would be appropriate. For something longer, use a mutex.</P>

        <Note>On a given system platform, there may not be a critical section mechanism, and the platform driver for that platform may just implement it using a mutex. But, still use them where appropriate since you'll still get the benefits when there is a real distinction, and everything will still work fine either way.</Note>

        <P>The only difference relative to the above example is that you would use a TCritSecLocker object to do the locking instead of a TMtxLocker as you would for a mutex.</P>

        <SubSecTitle>Events and Semaphores</SubSecTitle>

        <P>Events and semaphores are other common synchronization mechanisms. Here again, these are common computer science type topics so I won't try to explain them here. Of these two, events tend to be far and away the most used.</P>

        <P>Threads can block on an event waiting for it to be signaled. As always they should not just blindly block but block for a while and then see if they have been asked to shut down. If not, go back and block again for a little while.</P>

        <P>They can also wait on multiple events. The most common scenario is probably two events, one of which reflects incoming data available and the other which reflects outgoing data available. This allows you to create threads that can handle sending and receiving data in a very efficient manner, getting data to send from a queue and putting data received into a queue.</P>

        <P>Sockets can be associated with ane event which will be triggered when data is available, and that is usually how the incoming event is used in a standard TCP/IP based server.</P>


        <SecTitle>Sync vs. Synchronize</SecTitle>

        <P>A mutex is used to sychronize access to some shared data within some particular scope where it is locked. It doesn't guarantee that any other threads are at any particular place in their journey through code space, other than that they are <Italic>not</Italic> within that locked scope. For most purposes that is all that you care about.</P>

        <P>But there may be some scenarios where you want to be sure that another thread is at a particular place before you do something. Some reasons why you might want to do this might be:</P>

        <List>
            <LItem>If two threads use some shared values, probably class members, as an inexpensive means of inter-thread communications, so one thread may want know if another is at a specific place before it updates those members.</LItem>
            <LItem>If two threads work together and one thread accesses the data in many places and the other just one place and not very often, it can avoid either of from having to add synchronization calls at every access.</LItem>
        </List>

        <P>The TThread class provides a generic means for threads to do this kind of sync. A thread that allows itself to be sync'd will call Sync() at some defined place. If another thread has made a sync request, the thread that calls Sync(), the 'controlled' thread, will be blocked until the other thread lets it go. The 'controlling' thread calls WaitSync() to wait for the controlled thread to call Sync(). When WaitSync() returns, the controlled thread will be at the Sync() call and blocked. The controlling thread can then access any shared resources as desired. To let the blocked thread go, the controlling thread calls Release() to let the other thread go.</P>

        <Note>The controlling thread calls WaitSync() and Release on the other thread object, <Italic>not</Italic> on itself.</Note>

        <P>WaitSync() takes a timeout, so that it can give up if the other thread doesn't get to the sync point within a reasonable amount of time. If WaitSync() times out, then the sync request is automatically cancelled.</P>

        <P>A thread can call Sync() from multiple places, but there's no way for the controlling thread to know which one of them that thread is at. It just knows it is at one of them. They controlled thread could set some flag to indicate this by setting it just before it calls Sync().</P>

        <SecTitle>Queues</SecTitle>

        <P>The TQueue and TRefQueue collection classes (see Collections to the left) are designed specifically to handle a particular (and very common) type of synchronization issue. Any time you are writing a server program, it's common that you want to create a 'thread pool', which is just a bunch of already running threads that you can hand off incoming requests (from clients) to without the overhead of spinning up a new thread and tearing it down every time.</P>

        <P>Queues make this very easy by providing methods that worker threads can call to wait for work to do, and other methods that incoming client request handler threads can use to push work into the queue.</P>

        <P>So you create the queue thread safe, then you spin up all of the worker threads and they just block, waiting for queue input (following the above rules of course to check periodically for shutdown requests. So this makes the creation of various server type processes fairly straightforward, at least the thread pool part of it anyway.</P>


    </HelpText>

</HelpPage>
